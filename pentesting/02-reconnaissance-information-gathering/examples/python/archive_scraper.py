#!/usr/bin/env python3
"""
Archive.org Scraper
Scrapes historical data from the Wayback Machine.
"""

import sys
import requests
from typing import List, Dict
from datetime import datetime

class ArchiveScraper:
    def __init__(self, domain: str):
        self.domain = domain
        self.snapshots = []
    
    def get_snapshots(self, limit: int = 100) -> List[Dict]:
        """Get historical snapshots from Wayback Machine"""
        print(f"[*] Retrieving snapshots for {self.domain} from Wayback Machine...")
        
        try:
            url = f"http://web.archive.org/cdx/search/cdx"
            params = {
                'url': self.domain,
                'output': 'json',
                'limit': limit,
                'collapse': 'urlkey'
            }
            
            response = requests.get(url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                if len(data) > 1:  # First row is headers
                    for row in data[1:]:
                        self.snapshots.append({
                            'timestamp': row[1],
                            'url': row[2],
                            'status': row[4],
                            'mime': row[3]
                        })
        except Exception as e:
            print(f"[-] Error: {e}")
        
        return self.snapshots
    
    def get_snapshot_url(self, timestamp: str, original_url: str) -> str:
        """Get Wayback Machine URL for a specific snapshot"""
        return f"http://web.archive.org/web/{timestamp}/{original_url}"
    
    def get_first_snapshot(self) -> Dict:
        """Get the first (oldest) snapshot"""
        if not self.snapshots:
            self.get_snapshots()
        
        if self.snapshots:
            return self.snapshots[0]
        return None
    
    def get_latest_snapshot(self) -> Dict:
        """Get the latest snapshot"""
        if not self.snapshots:
            self.get_snapshots()
        
        if self.snapshots:
            return self.snapshots[-1]
        return None
    
    def search_by_date(self, year: int, month: int = None) -> List[Dict]:
        """Search snapshots by date"""
        if not self.snapshots:
            self.get_snapshots()
        
        results = []
        for snapshot in self.snapshots:
            timestamp = snapshot['timestamp']
            snap_year = int(timestamp[:4])
            snap_month = int(timestamp[4:6])
            
            if snap_year == year:
                if month is None or snap_month == month:
                    results.append(snapshot)
        
        return results
    
    def extract_interesting_urls(self) -> List[str]:
        """Extract interesting URLs from snapshots"""
        interesting_patterns = [
            '/admin', '/login', '/config', '/backup', '/test',
            '/api', '/internal', '/private', '/secret'
        ]
        
        interesting_urls = []
        for snapshot in self.snapshots:
            url = snapshot.get('url', '')
            for pattern in interesting_patterns:
                if pattern in url.lower():
                    interesting_urls.append(url)
                    break
        
        return list(set(interesting_urls))  # Remove duplicates
    
    def generate_report(self) -> str:
        """Generate archive scraping report"""
        if not self.snapshots:
            self.get_snapshots()
        
        report = f"# Archive.org Scraping Report for {self.domain}\n\n"
        report += f"**Total Snapshots Found**: {len(self.snapshots)}\n\n"
        
        if self.snapshots:
            first = self.get_first_snapshot()
            latest = self.get_latest_snapshot()
            
            if first:
                report += "## First Snapshot\n\n"
                report += f"**Date**: {first['timestamp']}\n\n"
                report += f"**URL**: {self.get_snapshot_url(first['timestamp'], first['url'])}\n\n"
            
            if latest:
                report += "## Latest Snapshot\n\n"
                report += f"**Date**: {latest['timestamp']}\n\n"
                report += f"**URL**: {self.get_snapshot_url(latest['timestamp'], latest['url'])}\n\n"
            
            # Interesting URLs
            interesting = self.extract_interesting_urls()
            if interesting:
                report += "## Interesting URLs Found\n\n"
                for url in interesting[:20]:  # Limit to first 20
                    report += f"- {url}\n"
                report += "\n"
            
            # Timeline
            report += "## Snapshot Timeline\n\n"
            report += "| Date | URL | Status |\n"
            report += "|------|-----|--------|\n"
            
            for snapshot in self.snapshots[:20]:  # Limit to first 20
                timestamp = snapshot['timestamp']
                date_str = f"{timestamp[:4]}-{timestamp[4:6]}-{timestamp[6:8]}"
                report += f"| {date_str} | {snapshot['url'][:50]}... | {snapshot['status']} |\n"
            report += "\n"
        
        report += "## Usage Notes\n\n"
        report += "1. Wayback Machine may have rate limits\n"
        report += "2. Some snapshots may not be accessible\n"
        report += "3. Historical data may reveal sensitive information\n"
        report += "4. Use responsibly and ethically\n\n"
        
        return report

def main():
    if len(sys.argv) < 2:
        print("Usage: python archive_scraper.py <domain>")
        print("Example: python archive_scraper.py example.com")
        sys.exit(1)
    
    domain = sys.argv[1]
    
    scraper = ArchiveScraper(domain)
    
    report = scraper.generate_report()
    
    filename = f"archive_scrape_{domain.replace('.', '_')}.md"
    with open(filename, 'w') as f:
        f.write(report)
    
    print(f"[+] Archive scraping complete")
    print(f"[+] Found {len(scraper.snapshots)} snapshots")
    print(f"[+] Report saved to {filename}")

if __name__ == '__main__':
    main()

