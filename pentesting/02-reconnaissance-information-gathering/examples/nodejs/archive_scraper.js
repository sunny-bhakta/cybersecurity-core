#!/usr/bin/env node
/**
 * Archive.org Scraper
 * Scrapes historical data from the Wayback Machine.
 */

const https = require('https');
const fs = require('fs');

class ArchiveScraper {
    constructor(domain) {
        this.domain = domain;
        this.snapshots = [];
    }

    async getSnapshots(limit = 100) {
        console.log(`[*] Retrieving snapshots for ${this.domain} from Wayback Machine...`);
        
        try {
            const url = `http://web.archive.org/cdx/search/cdx?url=${this.domain}&output=json&limit=${limit}&collapse=urlkey`;
            const data = await this.makeRequest(url);
            
            if (Array.isArray(data) && data.length > 1) {
                // First row is headers
                for (let i = 1; i < data.length; i++) {
                    const row = data[i];
                    this.snapshots.push({
                        timestamp: row[1],
                        url: row[2],
                        status: row[4],
                        mime: row[3]
                    });
                }
            }
        } catch (err) {
            console.log(`[-] Error: ${err.message}`);
        }
        
        return this.snapshots;
    }

    getSnapshotUrl(timestamp, originalUrl) {
        return `http://web.archive.org/web/${timestamp}/${originalUrl}`;
    }

    getFirstSnapshot() {
        if (this.snapshots.length === 0) return null;
        return this.snapshots[0];
    }

    getLatestSnapshot() {
        if (this.snapshots.length === 0) return null;
        return this.snapshots[this.snapshots.length - 1];
    }

    searchByDate(year, month = null) {
        const results = [];
        
        for (const snapshot of this.snapshots) {
            const timestamp = snapshot.timestamp;
            const snapYear = parseInt(timestamp.substring(0, 4));
            const snapMonth = parseInt(timestamp.substring(4, 6));
            
            if (snapYear === year) {
                if (month === null || snapMonth === month) {
                    results.push(snapshot);
                }
            }
        }
        
        return results;
    }

    extractInterestingUrls() {
        const interestingPatterns = [
            '/admin', '/login', '/config', '/backup', '/test',
            '/api', '/internal', '/private', '/secret'
        ];
        
        const interestingUrls = [];
        
        for (const snapshot of this.snapshots) {
            const url = snapshot.url || '';
            for (const pattern of interestingPatterns) {
                if (url.toLowerCase().includes(pattern)) {
                    interestingUrls.push(url);
                    break;
                }
            }
        }
        
        // Remove duplicates
        return [...new Set(interestingUrls)];
    }

    makeRequest(url) {
        return new Promise((resolve, reject) => {
            https.get(url, { timeout: 30000 }, (res) => {
                let data = '';
                res.on('data', (chunk) => {
                    data += chunk;
                });
                res.on('end', () => {
                    try {
                        resolve(JSON.parse(data));
                    } catch (e) {
                        resolve(data);
                    }
                });
            }).on('error', (err) => {
                reject(err);
            });
        });
    }

    async generateReport() {
        if (this.snapshots.length === 0) {
            await this.getSnapshots();
        }
        
        let report = `# Archive.org Scraping Report for ${this.domain}\n\n`;
        report += `**Total Snapshots Found**: ${this.snapshots.length}\n\n`;
        
        if (this.snapshots.length > 0) {
            const first = this.getFirstSnapshot();
            const latest = this.getLatestSnapshot();
            
            if (first) {
                report += `## First Snapshot\n\n`;
                report += `**Date**: ${first.timestamp}\n\n`;
                report += `**URL**: ${this.getSnapshotUrl(first.timestamp, first.url)}\n\n`;
            }
            
            if (latest) {
                report += `## Latest Snapshot\n\n`;
                report += `**Date**: ${latest.timestamp}\n\n`;
                report += `**URL**: ${this.getSnapshotUrl(latest.timestamp, latest.url)}\n\n`;
            }
            
            const interesting = this.extractInterestingUrls();
            if (interesting.length > 0) {
                report += `## Interesting URLs Found\n\n`;
                interesting.slice(0, 20).forEach(url => {
                    report += `- ${url}\n`;
                });
                report += `\n`;
            }
            
            report += `## Snapshot Timeline\n\n`;
            report += `| Date | URL | Status |\n`;
            report += `|------|-----|--------|\n`;
            
            this.snapshots.slice(0, 20).forEach(snapshot => {
                const timestamp = snapshot.timestamp;
                const dateStr = `${timestamp.substring(0, 4)}-${timestamp.substring(4, 6)}-${timestamp.substring(6, 8)}`;
                const url = snapshot.url.length > 50 ? snapshot.url.substring(0, 50) + '...' : snapshot.url;
                report += `| ${dateStr} | ${url} | ${snapshot.status} |\n`;
            });
            report += `\n`;
        }
        
        report += `## Usage Notes\n\n`;
        report += `1. Wayback Machine may have rate limits\n`;
        report += `2. Some snapshots may not be accessible\n`;
        report += `3. Historical data may reveal sensitive information\n`;
        report += `4. Use responsibly and ethically\n\n`;
        
        return report;
    }
}

// Main execution
async function main() {
    if (process.argv.length < 3) {
        console.log('Usage: node archive_scraper.js <domain>');
        console.log('Example: node archive_scraper.js example.com');
        process.exit(1);
    }
    
    const domain = process.argv[2];
    
    const scraper = new ArchiveScraper(domain);
    
    const report = await scraper.generateReport();
    
    const filename = `archive_scrape_${domain.replace(/\./g, '_')}.md`;
    fs.writeFileSync(filename, report, 'utf8');
    
    console.log(`[+] Archive scraping complete`);
    console.log(`[+] Found ${scraper.snapshots.length} snapshots`);
    console.log(`[+] Report saved to ${filename}`);
}

if (require.main === module) {
    main().catch(console.error);
}

module.exports = ArchiveScraper;

